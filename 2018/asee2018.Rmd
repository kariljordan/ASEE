# Two-day workshops build skills and confidence for researchers to work with data.
Authors: [Kari L. Jordan](https://github.com/kariljordan), [Elizabeth Wickes](https://github.com/elliewix) [Jonah Duckles](https://github.com/jduckles), [Ben Marwick](https://github.com/benmarwick)

`r format(Sys.Date(), "%B %Y")`

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = FALSE,
               message = FALSE,
               warning = FALSE)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(purrr)
library(tibble)
library(DBI)
library(ggmap)
library(likert)
library(mapproj)
library(RColorBrewer)
library(srvyr)
```


```{r include=FALSE}
round1data <- readr::read_csv("https://raw.githubusercontent.com/kariljordan/ASEE/master/2018/data_20170701.csv")
round2data <- readr::read_csv("https://raw.githubusercontent.com/kariljordan/ASEE/master/2018/data_20171108.csv")
```


```{r include = FALSE}
# Use prop.table() to calculate percentages on a single column when you want to show highlights in the data
# Example: Change in Confidence
ChangeInConfidence <- round(prop.table(table(data$`ChangeInConfidence`)) * 100)
```

```{r}
# Function that makes a table of counts and percentages
# question_n is set by default to the number of respondents in the survey (504). This value may have to be set by question. 
question_n <- nrow(round2data)

tally_and_perc <- function(df, colname, na.rm = FALSE, question_n){
  quo_colname <- enquo(colname)

  df %>% 
    group_by(!!quo_colname) %>% 
    tally() %>% 
    filter(if_else(rep(na.rm, nrow(.)),
                  !is.na(!!quo_colname),
                  as.logical(rep(1, nrow(.))))) %>% 
    mutate(`%` = round(n / question_n * 100, 1)) 
}

# function to compute number of non-NA responses to a question

n_responses_to_the_question <- function(df, from_colname, to_colname) {
  
  quo_from_colname <- enquo(from_colname)
  quo_to_colname <- enquo(to_colname)
  
  rowsums <- 
df %>%
  select(UQ(quo_from_colname):UQ(quo_to_colname)) %>% 
  # check that each row has a value for at least one col
  # convert to numeric, if NA, then put a zero, otherwise 1
  map_df(., ~ifelse(is.na(.x), 0, 1)) %>% 
  # sum to see if any rows have no reponses
  rowSums() 

# for all behaviours
idx <- ifelse(rowsums == 0, FALSE, TRUE)
sum(idx)
}
```
# Introduction


# Highlights



# Respondent Demographics
```{r}
# Field of work, research, or study. Responses are in columns 'Field' through 'Column12'

n_responses_to_field_question <- 
  n_responses_to_the_question(round2data, 
                              from_colname = Field, 
                              to_colname = Column12)
                              
field_perc <- 
round2data %>%
  select(Field:Column12) %>% 
  gather(col, field_perc) %>% 
  group_by(field_perc) %>% 
  tally_and_perc(field_perc, 
                 na.rm = TRUE, 
                 question_n = n_responses_to_field_question) %>%
  filter(!is.na(field_perc)) %>% 
  arrange(desc(n)) %>%
  rename(Field = field_perc) 

kable(field_perc, 
      format = "markdown", 
      digits = getOption("digits"), 
      row.names = NA, 
      col.names = NA, 
    caption = NULL, 
    escape = TRUE)
```

```{r}
# Status of Respondents
status = c("Undergraduate Student", "Graduate Student", "Postdoc", "Faculty", "Industry", "Academic Research Staff", "Other Academic Staff", "Other (please specify)")
status = factor(status)

round2data$Status = factor(round2data$Status, levels = status)

round2data_status_tally <- 
  round2data %>% 
  group_by(Status) %>% 
  tally() %>% 
  filter(!is.na(Status)) %>% 
  mutate(perc = round(n/sum(n) * 100, 0))

ggplot(round2data_status_tally, 
       aes(Status, y = 100 * (n/sum(n)),
           n)) +
  geom_bar(stat = "identity", fill="orange") +
  geom_text(aes(label=n), size= 4, vjust=-0.25) +
  scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
  theme_classic() +
  xlab("Status") +
  ylab("% Respondents") +
  ggtitle("Figure 1: Respondent's Status") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_classic(base_size = 14)
ggsave("figures/status.png")
```

 
```{r}
# Plot includes Ben's tip to add a percent column to the data_country_tally data frame 
# before it goes into the ggplot() function. Then you should be able to use reorder on that column name in the ggplot() function
round1data_country_tally <-
round1data %>%
  group_by(Country) %>%
  tally(sort = TRUE) %>%
  mutate(perc = round(100 * (n/sum(n)), 1)) %>% # add the % col
  filter(!is.na(Country)) %>%
  arrange(desc(n))

ggplot(round1data_country_tally,
       aes(reorder(Country, perc),
           perc)) +
  geom_bar(stat = "identity", fill = "orange") +
  theme_classic() +
  xlab("") +
  ylab("Percentage of all participants") +
  coord_flip() +
  ggtitle("Figure 2: Workshop Respondents by Country") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw(base_size = 14)
ggsave("figures/percent_by_country.png")
```

```{r include=FALSE}
# If interested in seeing the open-ended responses for Position: Other, run this code.
round2data_field_other_tally <- 
  round2data %>% 
  group_by(`FieldOther`) %>% 
  tally() %>% 
  filter(!is.na(`FieldOther`))
kable(round2data_field_other_tally, format = "markdown", row.names = FALSE, col.names = c("Field-Other", "# Respondents"))
```

```{r include=FALSE}
# If interested in seeing the open-ended responses for Status: Other, run this code.
round2data_status_other_tally <-
  round2data %>%
  group_by(`StatusOther`) %>%
  tally() %>%
  filter(!is.na(`StatusOther`))
kable(round2data_status_other_tally, format = "markdown", row.names = FALSE, col.names = c("Status-Other", "# Respondents"))
```

```{r}
# Code for involvement (rows Involvement through Column57)
# I want to use the tally_and_perc function, but don't know where to put the question_n
Carpentry_Involvement <- 
round2data %>%
  select(`Involvement`:Column57) %>% 
  gather(col, Carpentry_Involvement) %>% 
  group_by(Carpentry_Involvement) %>% 
  tally() %>% 
  filter(!is.na(Carpentry_Involvement)) %>% 
  arrange(desc(n)) %>% 
  rename(`Involvement Since Attending a Carpentry Workshop` = Carpentry_Involvement)
kable(Carpentry_Involvement)
```



```{r}
# How long ago did you attend a workshop?
 round2data_time_since_tally <- 
  round2data %>% 
  group_by(`TimeSinceWorkshop`) %>% 
  tally() %>% 
  filter(!is.na(`TimeSinceWorkshop`)) 

# Use the code below to include a table of how long ago respondents attended a workshop
# kable(round2data_time_since_tally, format = "markdown", row.names = FALSE, col.names = c("Time", "n"), caption = "How Recently Did Respondents Complete a Workshop?")

ggplot(round2data_time_since_tally, 
       aes(`TimeSinceWorkshop`, y = 100 * (n/sum(n)),
           n)) +
  geom_bar(stat = "identity", fill="orange") +
  geom_text(aes(label=n), size= 4 , vjust=-0.25) +
  scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
  theme_classic() +
  xlab("Time Since Attending Carpentry Workshop") +
  ylab("% Respondents") +
  ggtitle("Figure 3: XX") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_classic(base_size = 14)
ggsave("figures/time_since_attending_workshop.png")
```

```{r}
# Number of workshops attended
round2data_workshops_tally <- 
  round2data %>% 
  group_by(`NumWorkshops`) %>% 
  tally() %>% 
  filter(!is.na(`NumWorkshops`))

# Use the code below to include a table of the number of workshops respondents attended
#kable(round2data_workshops_tally, format = "markdown", row.names = FALSE, col.names = c("# Wrkshps", "n"), caption = "Number of Workshops Attended")

ggplot(round2data_workshops_tally, 
       aes(`NumWorkshops`, y = 100 * (n/sum(n)),
           n)) +
  geom_bar(stat = "identity", fill="orange") +
  geom_text(aes(label=n), size= 4, vjust=-0.25) +
  scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
  theme_classic() +
  xlab("# Workshops Attended") +
  ylab("% Respondents") +
  ggtitle("Figure 4: XX") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_classic(base_size = 14)
ggsave("figures/number_workshops_attended.png")
```

### Workshop Content

```{r}
# What content was covered
# Responses are in columns 'ContentCovered' through 'Column23'
# Ben's tip to use 'gather' to go from wide to long format
workshop_tools <- 
 round2data %>%
 select(`ContentCovered`:Column23) %>% 
 gather(col, workshop_tools) %>% 
 group_by(workshop_tools) %>% 
 tally() %>% 
 filter(!is.na(workshop_tools)) %>% 
 arrange(desc(n)) %>%
 rename(`ContentCovered` = workshop_tools)

# Use the line below to provide a table of the tools covered. 
# Respondents were asked to check all that apply.
kable(workshop_tools, caption = "Tools Covered") 

# Ben's tip to use in-line text
# This code produces results to use in the text of the report
Git <- workshop_tools[workshop_tools$Content == 'Git', ]$n
Python <- workshop_tools[workshop_tools$Content == 'Python', ]$n
Unix_Shell <- workshop_tools[workshop_tools$Content == 'Unix Shell', ]$n
R <- workshop_tools[workshop_tools$Content == 'R', ]$n
SQL <- workshop_tools[workshop_tools$Content == 'SQL', ]$n
OpenRefine <- workshop_tools[workshop_tools$Content == 'OpenRefine', ]$n
Spreadsheets <- workshop_tools[workshop_tools$Content == 'Spreadsheets', ]$n
Cloud_Computing <- workshop_tools[workshop_tools$Content == 'Cloud Computing', ]$n
MATLAB <-  workshop_tools[workshop_tools$Content == 'MATLAB', ]$n
Mercurial <-  workshop_tools[workshop_tools$Content == 'Mercurial', ]$n
```


```{r}
# The code segment below from Ben Marwick will show the most combinations of tools covered in our workshops.

n_responses_to_tools_question <- 
  n_responses_to_the_question(round2data, 
                              from_colname = ContentCovered, 
                              to_colname = Column23)

tools_cols <- 
round2data %>%
  select(ContentCovered:Column23)

list_of_tools_per_person <- list()
for(i in seq_len(nrow(tools_cols))) {
  ii <- quo(i)
  
  list_of_tools_per_person[[i]] <- 
  tools_cols %>% 
    slice(!!ii) %>% 
          c(., recursive=TRUE) %>%
          unname %>% 
    na.omit() %>% 
    as.vector()
}

# The code segment below from Ben Marwick will get the tally of combinations of tools and produce a table.
tool_combs <- 
purrr::map_chr(list_of_tools_per_person,
               ~paste0(.x, collapse = " "))

tool_combs_df <- 
tool_combs %>% 
  as_data_frame() %>% 
  group_by(value) %>% 
  tally() %>% 
  mutate(`%` = round(n / sum(n) * 100, 1)) %>% 
  arrange(desc(n)) %>% 
  filter(value != "")

# Top combinations as entered by respondants
colnames <- c("Frequency of Tools Covered", "n", "%")
kable(tool_combs_df[1:10, ], row.names = NA, col.names = colnames, caption = "Combination of Tools Covered")
```


```{r}
# The code segment below from Ben Marwick will give a matrix of the combinations of tools used.
m <- as.matrix(tools_cols) 
# The unique values in the matrix
vals <- sort(unique(as.vector(m)))

# Rearrange the data so that each value is a column
bigm <- t(apply(m, 1, function(row) match(vals, row, nomatch=0)))
colnames(bigm) <- vals

# Count the co-occurences of each value (diagonal is total number of rows with that value)
tool_co_occurences  <- as.data.frame(crossprod(bigm>0))
kable(tool_co_occurences, row.names = TRUE, caption = "Matrix of Common Tools Covered")
```

### Programming Usage Pre- and Post Workshop

```{r}
# The code below can be used to get a table and plot of the number of respondents for programming usage
# pre workshop
# Naupaka's tip so pre- and post-responses match
round2data_paired_plot <- round2data
levels(round2data$`ProgrammingBefore`)[2] <- "I have not been using tools like these."
 
# Programming Usage Pre-Carpentry Workshop [Absolute Plot]
programming = c("I had not been using tools like these.", "Less than once per year.", "Several times per year.", "Monthly.", "Weekly.", "Daily.")
programming = factor(programming)
 
  round2data_usage_tally <- 
   round2data %>% 
   group_by(`ProgrammingBefore`) %>% 
   tally() %>% 
   filter(!is.na(`ProgrammingBefore`)) 

  kable(round2data_usage_tally, caption = "Prior Programming of Respondents")
 
  ggplot(round2data_usage_tally, 
        aes(`ProgrammingBefore`, n)) +
   geom_bar(stat = "identity", fill="orange") +
   geom_text(aes(label=n), size= 4) +
   scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
   theme_classic() +
   xlab("Programming Usage") +
   ylab("# Respondents") +
   ggtitle("Figure 5: XX") +
   theme(plot.title = element_text(hjust = 0.5)) +
   theme_classic(base_size = 14)
ggsave("figures/programming_usage_pre_absolute.png")
# Why aren't the levels showing in the correct order on the plot?
```

```{r}
# The code below is for pre-workshop programming usage reported as a percentage.
# Programming Pre-Carpentry Workshop [Percentage Plot]
 round2data %>%
  select(`ProgrammingBefore`) %>%
   group_by(`ProgrammingBefore`) %>%
   tally() %>%
   filter(!is.na(`ProgrammingBefore`)) %>%
   mutate(`ProgrammingBefore` =     factor(`ProgrammingBefore`, levels = programming)) %>%
   ggplot(aes(x = `ProgrammingBefore`, y = 100 * (n/sum(n)))) +
     geom_bar(stat = "identity", position = "dodge", fill = "orange") +
     geom_text(aes(label=n), size= 4) +
     scale_x_discrete(labels = function(x) lapply(strwrap(x,
                                                          width = 10,
                                                          simplify = FALSE),
                                                  paste,
                                                  collapse = "\n")) +
     theme_classic() +
     xlab("Programming Usage") +
     ylab("% respondents") +
     ggtitle("Figure XX: Pre") +
     theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic(base_size = 14)
ggsave("figures/programming_usage_pre_percent.png")
```    

```{r}
# The code below is for post-workshop programming usage (count)
# Programming Usage Post-Carpentry Workshop [Absolute Plot]
  programming = c("I have not been using tools like these.", "Less than once per year.", "Several times per year.", "Monthly.", "Weekly.", "Daily.")
  programming = factor(programming)
 
 round2data$`ProgrammingSince` = factor(round2data$`ProgrammingSince`, levels = programming)
 
  round2data_usage_tally <- 
   round2data %>% 
   group_by(`ProgrammingSince`) %>% 
   tally() %>% 
   filter(!is.na(`ProgrammingSince`)) 
 
 kable(round2data_usage_tally)
 
  ggplot(round2data_usage_tally, 
        aes(`ProgrammingSince`, n)) +
   geom_bar(stat = "identity", fill="orange") +
   geom_text(aes(label=n), size= 4) +
   scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
   theme_classic() +
   xlab("Programming Usage") +
   ylab("# Respondents") +
   ggtitle("Figure XX: Post") +
   theme(plot.title = element_text(hjust = 0.5)) +
   theme_classic(base_size = 14)
ggsave("figures/programming_usage_post_absolute.png")
```

```{r}
# The code below is for post-workshop programming usage as a percent
#Programming Usage Post-Carpentry Workshop [Percentage Plot]
round2data %>%
select(`ProgrammingSince`) %>%
group_by(`ProgrammingSince`) %>%
tally() %>%
filter(!is.na(`ProgrammingSince`)) %>%
mutate(`ProgrammingSince` = factor(`ProgrammingSince`, levels = programming)) %>%
ggplot(aes(x = `ProgrammingSince`, y = 100 * (n/sum(n)))) +
geom_bar(stat = "identity", position = "dodge", fill = "orange", na.rm = TRUE ) +
geom_text(aes(label=n), size= 4) + # Adds count to top of bar
scale_x_discrete(labels = function(x) lapply(strwrap(x,
                                                         width = 10,
                                                         simplify = FALSE),
                                                 paste,
                                                 collapse = "\n")) +
    theme_classic() +
    xlab("") +
    ylab("% respondents") +
    ggtitle("Figure XX: post") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic(base_size = 14)
ggsave("figures/programming_usage_post_percent.png")
```

```{r fig.cap=paste("Synopsis: Respondents were asked how often they use programing languages (R, Python, etc.), databases (Access, SQL, etc.), version control software and/or the shell before completing a Carpentries workshop, and since completing a Carpentries workshop.")}
# The code below is for Pre/Post plots of programming usage
# It includes tips from Ben and Naupaka 
# Make the unique values the same
round2data$`ProgrammingBefore` <- 
  gsub("I had not been using tools like these.",
       "I have not been using tools like these.", 
       round2data$`ProgrammingBefore`)

round2data$`ProgrammingBefore` <- 
  factor(round2data$`ProgrammingBefore`, 
         levels = programming)

pre_and_post_usage <- 
round2data %>%
  select(`ProgrammingBefore`, 
          `ProgrammingSince`) %>%
  gather() %>%
  group_by(key, value) %>%
  tally() %>%
  mutate( perc = 100 * (n/sum(n))) %>%
  filter(!is.na(key),
         !is.na(value)) 

  ggplot(pre_and_post_usage, 
         aes(x = factor(value, 
                        levels = programming), 
             y = perc, 
             fill = key)) +
    geom_bar(stat = "identity", 
             position = "dodge") +
    geom_text(aes(label=n), size= 4, vjust=-0.25, position = position_dodge(width = 1)) +
    scale_x_discrete(labels = function(x) lapply(strwrap(x,
                                                         width = 10,
                                                         simplify = FALSE),
                                                 paste,
                                                 collapse = "\n")) +
    theme_classic() +
    xlab("Programming Usage") +
    ylab("% Respondents") +
    scale_fill_discrete(name = "",
                        labels = c("Before Workshop", "After Workshop")) +
    ggtitle("Respondents' Programming Usage Increased") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic(base_size = 14)
ggsave("figures/change_in_programming_usage.png") 
```



```{r}
# The code below from Ben provides a chi-square plot of the pre/post residuals
# Let's talk about this plot and whether to include it.
pre_and_post_test <- 
pre_and_post_usage %>% 
  select(-perc) %>% 
  spread(value, n) %>% 
  ungroup()  

# chi-sq test
pre_and_post_test_result <- 
  chisq.test(pre_and_post_test[ , !names(pre_and_post_test) == 'key'])

# standardised residuals
stdres <- data.frame(t(pre_and_post_test_result$stdres))
names(stdres) <- pre_and_post_test$key
stdres$freq <- row.names(stdres)

# just show post-workshop
stdres <- stdres[, c(2,3)]

names(stdres) <- rev(c("Frequency", "Residual"))

# large positive residuals means there were more xxx than the hypothesis of independence predicts. Where are our large +ve residuals?

# Contribution in percentage (%)
# The contribution (in %) of a given cell to the total Chi-square score is calculated as follows:
contrib <- 100 * pre_and_post_test_result$residuals^2 / pre_and_post_test_result$statistic
# scale 0 to 1 to use as alpha
range0to1 <- function(x){(x-min(x))/(max(x)-min(x))}
# reorder to match order of programming factor
contrib_0_to_1 <- as.vector(range0to1(contrib))[c(3,5,9,7,11,1)]

# colour +ve and -ve values
# http://stackoverflow.com/a/12910865/1036500
stdres$sign = ifelse(stdres$Residual >= 0, 
                          "positive", 
                          "negative")

# get the categories in a sensible order
ggplot(stdres,
       aes(factor(Frequency, 
                  levels = programming),
           Residual,
           fill = sign)) +
  geom_col(position = "dodge", 
           aes(alpha = contrib_0_to_1)) +
  xlab("") +
  ylab("Chi-square standardized residuals of\npost-workshop frequencies") +
  scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse = "\n")) +
  scale_fill_manual(name = "",
                      values = c("negative" = "red", 
                                 "positive" = "blue"),
                      labels = c("Fewer respondents than \nexpected assuming no effect", 
                                 "More respondents than \nexpected assuming no effect")) +
  ggtitle("Workshops result in respondents \nprogramming significantly more often") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_classic(base_size = 14) +
  scale_alpha_continuous("Contribution to \nchi-square value") +
   guides(fill=guide_legend(
                 keywidth = 0.1,
                 keyheight = 0.4,
                 default.unit = "inch")
      )
ggsave("figures/programming_post_workshop.png")
```

# Workshop Impact
```{r}
# Jonah's fix to include the correct levels. Variable was renamed to 'levels' 
# because 'order' is the name of a function in R.
# I am still not sure if this plot is 100% correct -KLJ

cols_with_Agree <- map_lgl(round2data, ~`%in%`("Agree", .x))
data_agree <-  round2data[ , cols_with_Agree]

levels = c("Strongly disagree", "Disagree", "Neutral", "Agree", "Strongly agree")

# Beth's tip to both order the factors based on levels and unify the factors
 factorfunction <- function(mydata, factlevel){
  factor(mydata, 
         levels=factlevel, 
         ordered = TRUE)
    fct_unify(mydata, 
              levels=factlevel)}
 # End tip 
 
 # Adjusting names of y axis labels
 names(data_agree) <- 
  c("Coding",
    "Confidence",
    "Career",
    "Motivation",
    "Reproducible",
    "Productivity",
    "Recognition")

data_agree_likert <- likert(data.frame(lapply(data_agree, factor, levels, ordered=TRUE)))

agree_or_strongly_agree_improved_3_things <- 
  data_agree %>% 
  select(Coding, Reproducible, Productivity) %>% 
  filter(Coding       %in% c("Agree", "Strongly agree") | # or
         Reproducible %in% c("Agree", "Strongly agree") |
         Productivity %in% c("Agree", "Strongly agree")) 

perc_agree_or_strongly_agree_improved_3_things <- 
  round(nrow(agree_or_strongly_agree_improved_3_things) / nrow(data_agree) * 100, 0)

received_professional_recognition <- 
  data_agree_likert$results %>% 
  filter(Item == "Recognition") %>% 
  select(Agree, `Strongly agree`) %>% 
  sum() %>% 
  round(0)
```


```{r}
title <- "Figure XX: Perception of Workshop Impact"		
plot(data_agree_likert, type =c("heat"), panel.arrange = NULL, panel.strip.color = "red", legend.position = "bottom") + ggtitle(title)
ggsave("figures/workshop_impact_heatmap.png")
```


```{r}
title <- "Perception of Workshop Impact"
 theme_update(plot.title = element_text(hjust = 0.5))
plot(data_agree_likert) + ggtitle(title) 

#print(class(data_agree))
 data_agree <- map_if(data_agree,
                     is.character,
                     as.factor)
 ggsave("figures/impact_likert.png")
 
 # The plot works, but the labels are not in the correct order.
```

### Behaviors Respondents Adopted
```{r include = FALSE}
# Code for behaviors adopted
# Responses are in columns 'Behaviors-Adopted' through 'Column32'

# How many responses do we have to this question?

responses_to_behaviours <- 
  n_responses_to_the_question(round2data, 
                              from_colname = `Behaviors`, 
                              to_colname = Column32)


# Use 'gather' to go from wide to long format
Behaviors_Adopted <- 
round2data %>%
  select(`Behaviors`:Column32) %>% 
  gather(col, Behaviors_Adopted) %>% 
  group_by(Behaviors_Adopted) %>% 
  tally_and_perc(Behaviors_Adopted, 
                 na.rm = TRUE, 
                 question_n = responses_to_behaviours) %>%
  filter(!is.na(Behaviors_Adopted)) %>% 
  arrange(desc(n))

#  how many rate either of these three?
#- data management and project organization practices : Behaviors-Adopted
#- used programming languages for automation : Column28
#- used version control to manage code : Column30

relevant_cols <- c("Behaviors-Adopted", "Column28", "Column30")

rowsums <- 
  round2data %>%
  select(one_of(relevant_cols)) %>% 
  # check that each row has a value for at least one col
  # convert to numeric, if NA, then put a zero, otherwise 1
  map_df(., ~ifelse(is.na(.x), 0, 1)) %>% 
  # sum to see if any rows have no reponses
  rowSums() 

# how many of these rows don't sum to zero?
idx <- ifelse(rowsums == 0, FALSE, TRUE)
number_that_adopted_any_of_those_three <- sum(idx)
```


```{r}
kable(Behaviors_Adopted, 
      format = "markdown", 
      digits = getOption("digits"), 
      row.names = NA, 
      col.names = NA, 
      caption = NULL, 
      format.args = list(), 
      escape = TRUE)
```


```{r}
# Code for matrix of behaviors (thanks Ben for the tip!)
# Combinations of behaviors adopted for individuals
behaviors_cols <- 
round2data %>%
  select(`Behaviors`:Column32)

# Matrix 
m <- as.matrix(behaviors_cols) 
# the unique values in the matrix
vals <- sort(unique(as.vector(m)))

# rearrange the data so that each value is a column
bigm <- t(apply(m, 1, function(row) match(vals, row, nomatch=0)))
colnames(bigm) <- vals

# count the co-occurences of each value (diagonal is total number of rows with that value)
behaviors_co_occurences  <- as.data.frame(crossprod(bigm>0))
kable(behaviors_co_occurences, row.names = TRUE, caption = "Matrix of Common Behaviors Adopted Post-Workshop")
```


```{r heatmap, fig.width=8, fig.height = 8}
library(tidyverse)
library(viridis)
library(stringr)
wrap_width <-  30
text_size <-  8
behaviors_co_occurences  %>% 
  as.matrix() %>% 
  reshape2::melt() %>% 
  as_tibble() %>% 
  ggplot(aes(x = Var1, 
             y = Var2, 
           fill = value)) +  
  geom_tile() +
  scale_fill_viridis() +
  coord_equal() +
  xlab("") +
  ylab("") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = wrap_width)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = wrap_width)) +
  theme(axis.text.x = element_text(angle = 90, size = text_size, vjust = 0.5, hjust = 1),
        axis.text.y = element_text(size = text_size))  +
  ggtitle("Heatmap of behaviour co-occurances")

ggsave("figures/behaviors_heatmap.png")

```

### Change in Confidence 

```{r}
# Code for change in confidence
confidence = c("I'm less confident now.", "I'm equally confident now.", "I'm more confident now.")
confidence = factor(confidence)

round2data$`ChangeInConfidence` = factor(round2data$`ChangeInConfidence`, levels = confidence)

data_change.in.confidence_tally <- 
  round2data %>% 
  group_by(`ChangeInConfidence`) %>% 
  tally() %>% 
  filter(!is.na(`ChangeInConfidence`)) %>% 
  mutate(perc = round(n / sum(n) * 100, 0 ))

# for in-text perc
perc_more_confident <- 
  data_change.in.confidence_tally %>% 
  filter(`ChangeInConfidence` == "I'm more confident now.") %>% 
  pull(perc)

# so we can say 'more than', round to nearest 5
mround <- function(x, base){ 
        base * round(x/base) 
} 

more_than_perc_more_confident <- mround(perc_more_confident,5) 
```




```{r}

# Use the code below for a table of the data.
# kable(data_change.in.confidence_tally, format = "markdown", row.names = FALSE, col.names = c("Change in Confidence", "%"))

ggplot(data_change.in.confidence_tally, 
       aes(`ChangeInConfidence`, y = 100 * (n/sum(n)),
           n)) +
   geom_bar(stat = "identity", fill = "orange") +
   geom_text(aes(label=n), size= 4, vjust=-0.25) +
   scale_x_discrete(labels = function(x) lapply(strwrap(x, width = 10, simplify = FALSE), paste, collapse="\n")) +
   theme_classic() +
   xlab("Change in Confidence") +
   ylab("% Respondents") +
   ggtitle("Figure XX") +
   theme(plot.title = element_text(hjust = 0.5)) +
   theme_bw(base_size = 14)
ggsave("figures/change_in_confidence.png")

# The data is missing!
```

### Usage of Tools for Research and/or Work

```{r}
# Data are in columns 'How-Tools-Learned-Help' through 'Column37'

# how many responses do we have to this question?

n_reponses_tools_learned_help <- 
    n_responses_to_the_question(round2data, 
                              from_colname = `HowToolsHelped`, 
                              to_colname = Column37)

# How many responded to either of these?
# They are improving my overall efficienct : How.Tools.Learned.Helped
# They are improving my ability to analyze data. : Column34
# They are improving my ability to manage data. : Column35

relevant_cols <- c("HowToolsHelped", "Column34", "Column35")

rowsums <- 
  round2data %>%
  select(one_of(relevant_cols)) %>% 
  # check that each row has a value for at least one col
  # convert to numeric, if NA, then put a zero, otherwise 1
  map_df(., ~ifelse(is.na(.x), 0, 1)) %>% 
  # sum to see if any rows have no reponses
  rowSums() 

idx <- ifelse(rowsums == 0, FALSE, TRUE)
number_that_tools_helped <- sum(idx)

how_help <- 
round2data %>%
  select(`HowToolsHelped`:Column37) %>% 
  gather(col, how_help) %>% 
  group_by(how_help) %>% 
  tally() %>%
  filter(!is.na(how_help)) %>% 
  arrange(desc(n)) %>% 
  rename(`HowToolsHelped` = how_help)

tools_helped <- 
round2data %>%
  select(`HowToolsHelped`:Column37) %>% 
  gather(col, tools_helped) %>% 
  group_by(tools_helped) %>% 
  tally_and_perc(tools_helped, na.rm = TRUE, question_n = n_reponses_tools_learned_help) %>%  
  filter(!is.na(tools_helped)) %>% 
  arrange(desc(n)) %>%
  rename(`How Tools Covered Have Helped` = tools_helped)
```

```{r}
kable(tools_helped, 
      format = "markdown", 
      row.names = FALSE, 
      caption = "Self-Reported Perception of How Tools Help Respondents")
```


### Contributions to Academic Writing

```{r}
# Code chunk for contributions to academic writing

# how many responded to this question?
rowsums <- 
round2data %>%
  select(`Writing`) %>% 
  # check that each row has a value for at least one col
  # convert to numeric, if NA, then put a zero, otherwise 1
  map_df(., ~ifelse(is.na(.x), 0, 1)) %>% 
  # sum to see if any rows have no reponses
  rowSums() 

# for all writing responses
idx <- ifelse(rowsums == 0, FALSE, TRUE)
n_responsed_to_writing <-  sum(idx)

# table about writing
round2data %>% 
  tally_and_perc(`Writing`, 
                 na.rm = TRUE, 
                 question_n = n_responsed_to_writing) %>% 
  kable()


writing = c("No.", "Not sure.", "Yes.")
writing = factor(writing)

round2data$`Writing` = factor(round2data$`Writing`, levels = writing)
Contributed_Writing <- round(prop.table(table(round2data$`Writing`)) * 100)
```



### Continuous Learning THIS IS WHERE I LEFT OFF
```{r}
# Code chunk for continuous learning 

Learning_Activities <- 
round2data %>%
  select(`Activities`:Column57) %>% 
  gather(col, Learning_Activities) %>% 
  group_by(Learning_Activities) %>% 
  tally() %>% 
  filter(!is.na(Learning_Activities)) %>% 
  mutate(`%` =round(n / sum(n) * 100, 0) ) %>% 
  arrange(desc(n)) %>% 
  rename(`Continuous Learning Post-Workshop` = Learning_Activities)

# To use code for Carpentry self-guided material in-line
carpentry_self_guided <- table(data$Column56)
```
A key finding is that learners continue their learning after completing a workshop. This can take many forms, including participating in short courses (in-person and online) and using self-guided material. We asked respondents to tell us which learning activities (for data management and analysis) they have participated in since completing a Carpentries workshop. The majority of respondents have used non-Carpentries, self-guided material, though `r carpentry_self_guided` responded having used Carpentries' self-guided material. Additionally, greater participation in meetups and in-person short courses has been reported by respondents.
```{r}
# Code chunk for table of continuous learning activities
kable(Learning_Activities, 
      format = "markdown", 
      row.names = FALSE, 
      col.names = c("Continuous Learning", "n", "%"), 
      caption = "Respondents Self-Reported Continuous Learning Activities")
```

The matrix below provides a breakdown of the combination of continuous learning activities respondents participated in. For example, 35 respondents have used both Carpentry and non-Carpentry self-guided material since attending a workshop.

```{r}
# Code for matrix of continuous learning (thanks Ben for the tip!)
# Combinations of continuous learning for individual
learning_cols <- 
data %>%
  select(`Activities`:Column57)

# Matrix 
m <- as.matrix(learning_cols) 
# the unique values in the matrix
vals <- sort(unique(as.vector(m)))

# rearrange the data so that each value is a column
bigm <- t(apply(m, 1, function(row) match(vals, row, nomatch=0)))
colnames(bigm) <- vals

# count the co-occurences of each value (diagonal is total number of rows with that value)
learning_co_occurences  <- as.data.frame(crossprod(bigm>0))
kable(learning_co_occurences, row.names = TRUE, caption = "Matrix of Common Continuous Learning Activities")
```

## Involvement in the Carpentries 

Learners often become actively involved with Software and/or Data Carpentry after completing a workshop. This involvement can take many forms - joining a mentoring group, becoming a workshop helper, or even becoming an instructor. The table provided below shows how respondents have involved themselves with the Carpentries since completing a workshop. Respondents were asked to check all that apply.

```{r}
# Code chunk for involvement with the Carpentries
# Data in columns 'Carpentry.Involvement through Column51
Carpentry_Involvement <- 
data %>%
  select(`Carpentry-Involvement`:Column51) %>% 
  gather(col, Carpentry_Involvement) %>% 
  group_by(Carpentry_Involvement) %>% 
  tally() %>% 
  filter(!is.na(Carpentry_Involvement)) %>% 
  arrange(desc(n)) %>% 
  rename(`Involvement Post-Workshop` = Carpentry_Involvement)

kable(Carpentry_Involvement, 
      row.names = FALSE, 
      caption = "Respondents Self-Reported Inolvement in the Carpentries Post-Workshop")
```

The matrix below displays frequent combinations of post-workshop involvement. For example, 16 of the respondents who became Carpentry instructors have attended at least one community call.

```{r}
# Code for matrix of involvement (thanks Ben for the tip!)
# Combinations of tools for individual
involvement_cols <- 
data %>%
  select(`Carpentry-Involvement`:Column51)

# Matrix tool-by-tool

m <- as.matrix(involvement_cols) 
# the unique values in the matrix
vals <- sort(unique(as.vector(m)))

# rearrange the data so that each value is a column
bigm <- t(apply(m, 1, function(row) match(vals, row, nomatch=0)))
colnames(bigm) <- vals

# count the co-occurences of each value (diagonal is total number of rows with that value)
involvement_co_occurences  <- as.data.frame(crossprod(bigm>0))
kable(involvement_co_occurences, 
      row.names = TRUE, 
      caption = "Matrix of Common Involvement")
```

```{r include=FALSE}
# Code chunk for whether respondents recommended a workshop
data_recommended_tally <-
  data %>% 
  group_by(Recommended) %>% 
  tally() %>% 
  filter(!is.na(Recommended)) %>% 
  arrange(desc(n))

# Code chunk for in-line text
said_yes <- data_recommended_tally[data_recommended_tally$Recommended == "Yes.", ]$n

# Table for responses of recommendations
# kable(data_recommended_tally)
```

```{r include=FALSE}
# Code chunk for likelihood of recommmending a Carpentry workshop
data_likelyrecommend_tally <-
  data %>% 
  group_by(`Likely-To-Recommend`) %>% 
  tally() %>% 
  filter(!is.na(`Likely-To-Recommend`)) %>% 
  arrange(desc(n))

# Table for responses
# kable(data_likelyrecommend_tally)
```

# Growth Opportunities

We are very excited to know that our workshops are having an impact on learners six months to a year after their attendance. Though the results of this survey are compelling, we do recognize issues for improvement. For example, `r USA_perc`% of respondents completed a workshop in the United States. We are continually discussing ways to broaden participation of our workshops in communities outside of the U.S.

We also realize there are some lessons that are not being taught as frequently as others, namely, the [Shell lesson](http://swcarpentry.github.io/shell-novice/) and the [SQL lesson](http://www.datacarpentry.org/sql-ecology-lesson/). We would like to understand why, and what we can do as a community to see an increase in this lesson being taught.

```{r}
# extract some values from the likert data to use in the text below
feeling_neutral_about_receiving_professional_recognition <- 
  data_agree_likert$results %>% 
  filter(Item == "Recognition") %>% 
  pull(Neutral) %>% 
  round(0)
  
either_disagreed_or_strongly_disagreed_received_any_professional_recognition <-   data_agree_likert$results %>% 
  filter(Item == "Recognition") %>% 
  mutate(dis_or_strongly_dis = sum(c(`Strongly disagree`, Disagree))) %>% 
  pull(dis_or_strongly_dis) %>% 
  round(0)
    
```


Lastly, `r feeling_neutral_about_receiving_professional_recognition`% of the respondents indicated feeling **neutral** about receiving professional recognition as a result of participating in a Carpentries workshop, and `r either_disagreed_or_strongly_disagreed_received_any_professional_recognition`% either disagreed or strongly disagreed that they had received any professional recognition. We would like to explore community development opportunities that will benefit learners’ personal as well as professional endeavours, so that time spent acquiring important skills for research is adequately recognized and possibly even rewarded.

# Summary

When our learners have successful experiences in our workshops, they are quick to share this positive experience with others. We asked respondents if they had already recommended our workshop, and `r Recommended[3]`% said yes!

This initial analysis of how Carpentries workshops have impacted learners long-term has been extremely insightful. In general, our workshops are helping learners improve their efficiency with managing and analyzing data. Learners are taking advantage of online resources to improve their skills, and many see value in becoming involved longer term with our community.

We will revisit this data when we compare the responses of learners who took a workshop more than a year ago with those who have taken a workshop less than six months ago and from six months to one year ago. Additionally, we will continue to use this survey every six months to collect data from new learners so we can monitor their progress, and add to our growing evidence base on assessment.


